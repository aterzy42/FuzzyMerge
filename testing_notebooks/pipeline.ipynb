{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff3dee3-cc71-4f6f-8703-8e492e9e9bb7",
   "metadata": {},
   "source": [
    "User pipeline:\n",
    "- Upload files (assume similar column structure across files)\n",
    "- Show columns and ask to select (text,numeric, date)\n",
    "- Continue merging\n",
    "- Give debug report for missing values that will be removed, words that will be mapped to a certain category, and duplicates. Show exact file and row where it is seen\n",
    "- Ask user to accept or reject and go back\n",
    "- If accept proceed to clean and merge\n",
    "- Create merged downloadable excel link\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41883880-ef9b-45c8-9d8a-b21ca827bb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94e9e4de-c209-424c-94a8-0aa6a3288d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rapidfuzz import fuzz,process\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fe8497-2159-4fd9-a16b-86a1033d60c3",
   "metadata": {},
   "source": [
    "Uploads files and check for errors with column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a31f390-8759-41e4-88e7-c7c28ae70ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Common Columns Across All Files:\n",
      "['Branch', 'Date', 'Product', 'Quantity']\n",
      "\n",
      "🧩 Unique Columns Per File:\n",
      "- sales_2024-03.xlsx: ['Revenue']\n",
      "- sales_2024-02.xlsx: ['Revenue']\n",
      "- sales_2024-01.xlsx: ['Rev']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(unique)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# ❓ Ask user what to do\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m decision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mDo you want to [F]ix files and retry or [C]ontinue with common columns? \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decision \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔁 Please edit your files and run the script again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/excel_ocr/lib/python3.9/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/excel_ocr/lib/python3.9/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# 📁 Folder containing your test data files\n",
    "input_folder = Path(\"../input/\")\n",
    "\n",
    "# 🗂️ Read headers from all Excel/CSV files\n",
    "file_headers = {}\n",
    "all_dataframes = []\n",
    "\n",
    "for file in input_folder.glob(\"*\"):\n",
    "    if file.suffix.lower() not in [\".csv\", \".xlsx\"]:\n",
    "        continue\n",
    "    try:\n",
    "        if file.suffix.lower() == \".xlsx\":\n",
    "            df = pd.read_excel(file, engine=\"openpyxl\")\n",
    "        else:\n",
    "            df = pd.read_csv(file)\n",
    "\n",
    "        df.columns = [col.strip().title() for col in df.columns]\n",
    "        file_headers[file.name] = set(df.columns)\n",
    "        df[\"__source_file__\"] = file.name  # optional: track source\n",
    "        df['row_number'] = df.index + 2\n",
    "        all_dataframes.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Could not read {file.name}: {e}\")\n",
    "\n",
    "# 🧠 Analyze headers\n",
    "header_sets = list(file_headers.values())\n",
    "\n",
    "if not header_sets:\n",
    "    print(\"❗ No valid files found.\")\n",
    "    exit()\n",
    "\n",
    "common_cols = set.intersection(*header_sets)\n",
    "all_cols = set.union(*header_sets)\n",
    "\n",
    "unique_cols_per_file = {\n",
    "    fname: cols - common_cols\n",
    "    for fname, cols in file_headers.items()\n",
    "}\n",
    "\n",
    "# 📊 Show results\n",
    "print(\"\\n✅ Common Columns Across All Files:\")\n",
    "print(sorted(common_cols))\n",
    "\n",
    "print(\"\\n🧩 Unique Columns Per File:\")\n",
    "for fname, unique in unique_cols_per_file.items():\n",
    "    if unique:\n",
    "        print(f\"- {fname}: {sorted(unique)}\")\n",
    "\n",
    "# ❓ Ask user what to do\n",
    "decision = input(\"\\nDo you want to [F]ix files and retry or [C]ontinue with common columns? \").strip().lower()\n",
    "\n",
    "if decision == 'f':\n",
    "    print(\"🔁 Please edit your files and run the script again.\")\n",
    "    exit()\n",
    "\n",
    "# 🧬 Merge only on common columns\n",
    "merged = pd.concat(\n",
    "    [df[list(common_cols) + ['__source_file__','row_number']] for df in all_dataframes],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b41662b-3448-4b6d-ae2b-49c69415f49a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Could not read ~$sales_2024-01.xlsx: File is not a zip file\n",
      "\n",
      "🧩 Found unique columns:\n",
      "\n",
      "📄 sales_2024-03.xlsx\n",
      "  • Revenue\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    ↪ Rename 'Revenue' to match another column? Enter name or leave blank to skip:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 sales_2024-02.xlsx\n",
      "  • Revenue\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    ↪ Rename 'Revenue' to match another column? Enter name or leave blank to skip:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 sales_2024-01.xlsx\n",
      "  • Balls\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    ↪ Rename 'Balls' to match another column? Enter name or leave blank to skip:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  • Rev\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    ↪ Rename 'Rev' to match another column? Enter name or leave blank to skip:  Revenue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final Common Columns Across All Files:\n",
      "['Branch', 'Date', 'Product', 'Quantity', 'Revenue']\n",
      "\n",
      "✅ Merged Data Preview:\n",
      "    Branch  Quantity       Date  Revenue  Product     __source_file__  \\\n",
      "0      NYC         4 2024-03-01   125.92  T-Shirt  sales_2024-03.xlsx   \n",
      "1  Chicago         3 2024-03-01    98.13      Hat  sales_2024-03.xlsx   \n",
      "2  Chicago         2 2024-03-01    77.36      Hat  sales_2024-03.xlsx   \n",
      "3  Chicago         4 2024-03-01    96.67    Socks  sales_2024-03.xlsx   \n",
      "4  Chicago         2 2024-03-01    37.17      Hat  sales_2024-03.xlsx   \n",
      "\n",
      "   row_number  \n",
      "0           2  \n",
      "1           3  \n",
      "2           4  \n",
      "3           5  \n",
      "4           6  \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# 📁 Folder containing your test data files\n",
    "input_folder = Path(\"../input/\")\n",
    "\n",
    "# 🗂️ Read headers from all Excel/CSV files\n",
    "file_headers = {}\n",
    "dataframes_by_file = {}\n",
    "\n",
    "for file in input_folder.glob(\"*\"):\n",
    "    if file.suffix.lower() not in [\".csv\", \".xlsx\"]:\n",
    "        continue\n",
    "    try:\n",
    "        if file.suffix.lower() == \".xlsx\":\n",
    "            df = pd.read_excel(file, engine=\"openpyxl\")\n",
    "        else:\n",
    "            df = pd.read_csv(file)\n",
    "\n",
    "        df.columns = [col.strip().title() for col in df.columns]\n",
    "        file_headers[file.name] = set(df.columns)\n",
    "        df[\"__source_file__\"] = file.name\n",
    "        df[\"row_number\"] = df.index + 2\n",
    "        dataframes_by_file[file.name] = df\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Could not read {file.name}: {e}\")\n",
    "\n",
    "# 🧠 First pass to find common & unique columns\n",
    "header_sets = list(file_headers.values())\n",
    "if not header_sets:\n",
    "    print(\"❗ No valid files found.\")\n",
    "    exit()\n",
    "\n",
    "common_cols = set.intersection(*header_sets)\n",
    "all_cols = set.union(*header_sets)\n",
    "\n",
    "unique_cols_per_file = {\n",
    "    fname: cols - common_cols\n",
    "    for fname, cols in file_headers.items()\n",
    "}\n",
    "\n",
    "# 🧩 Ask user about unique columns\n",
    "print(\"\\n🧩 Found unique columns:\")\n",
    "for fname, uniques in unique_cols_per_file.items():\n",
    "    if not uniques:\n",
    "        continue\n",
    "    print(f\"\\n📄 {fname}\")\n",
    "    for col in sorted(uniques):\n",
    "        print(f\"  • {col}\")\n",
    "        suggestion = input(f\"    ↪ Rename '{col}' to match another column? Enter name or leave blank to skip: \").strip()\n",
    "        if suggestion:\n",
    "            # Rename in the actual DataFrame and update header record\n",
    "            df = dataframes_by_file[fname]\n",
    "            if col in df.columns:\n",
    "                df.rename(columns={col: suggestion}, inplace=True)\n",
    "                file_headers[fname].remove(col)\n",
    "                file_headers[fname].add(suggestion)\n",
    "\n",
    "# 🔁 Recompute common columns after renaming\n",
    "header_sets = list(file_headers.values())\n",
    "common_cols = set.intersection(*header_sets)\n",
    "all_dataframes = list(dataframes_by_file.values())\n",
    "\n",
    "if not common_cols:\n",
    "    print(\"❌ No common columns found even after renaming.\")\n",
    "    exit()\n",
    "\n",
    "# 🧬 Merge only on common columns\n",
    "merged = pd.concat(\n",
    "    [df[list(common_cols) + ['__source_file__', 'row_number']] for df in all_dataframes],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# ✅ Show results\n",
    "print(\"\\n✅ Final Common Columns Across All Files:\")\n",
    "print(sorted(common_cols))\n",
    "\n",
    "print(\"\\n✅ Merged Data Preview:\")\n",
    "print(merged.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de12ed6f-2cea-4674-9e07-a55bdb7710de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(878, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67098c39-514b-4027-a71f-393047042f23",
   "metadata": {},
   "source": [
    "Figure out data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85103b37-dc9d-4083-a800-8125041ab5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Inferred Data Types:\n",
      "- Branch: string\n",
      "- Quantity: numeric\n",
      "- Date: datetime\n",
      "- Revenue: numeric\n",
      "- Product: string\n",
      "\n",
      "🛠️ Adjust data types if needed:\n",
      "Type one of: string, numeric, datetime. Leave blank to accept default.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Branch [string]:  \n",
      "Quantity [numeric]:  \n",
      "Date [datetime]:  \n",
      "Revenue [numeric]:  \n",
      "Product [string]:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Converting columns...\n",
      "✔️ Branch converted to string\n",
      "✔️ Quantity converted to numeric\n",
      "✔️ Date converted to datetime\n",
      "✔️ Revenue converted to numeric\n",
      "✔️ Product converted to string\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 🔍 Infer data types using Pandas\n",
    "print(\"\\n📊 Inferred Data Types:\")\n",
    "dtype_map = {}\n",
    "conversion_funcs = {\n",
    "    \"datetime\": pd.to_datetime,\n",
    "    \"numeric\": pd.to_numeric,\n",
    "    \"string\": lambda x: x.astype(str)\n",
    "}\n",
    "\n",
    "for col, dtype in merged.dtypes.items():\n",
    "    if col in [\"__source_file__\", \"row_number\"]:\n",
    "        continue\n",
    "    if pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "        inferred = \"datetime\"\n",
    "    elif pd.api.types.is_numeric_dtype(dtype):\n",
    "        inferred = \"numeric\"\n",
    "    else:\n",
    "        inferred = \"string\"\n",
    "    dtype_map[col] = inferred\n",
    "    print(f\"- {col}: {inferred}\")\n",
    "\n",
    "# ✍️ Ask user to confirm or override\n",
    "print(\"\\n🛠️ Adjust data types if needed:\")\n",
    "print(\"Type one of: string, numeric, datetime. Leave blank to accept default.\\n\")\n",
    "\n",
    "for col, default_type in dtype_map.items():\n",
    "    user_input = input(f\"{col} [{default_type}]: \").strip().lower()\n",
    "    if user_input in conversion_funcs:\n",
    "        dtype_map[col] = user_input\n",
    "\n",
    "# ✅ Apply conversions\n",
    "print(\"\\n🔄 Converting columns...\")\n",
    "for col, dtype in dtype_map.items():\n",
    "    if col in [\"__source_file__\", \"row_number\"]:\n",
    "        continue\n",
    "    try:\n",
    "        if dtype == \"string\":\n",
    "            merged[col] = merged[col].astype(str)\n",
    "        elif dtype == \"numeric\":\n",
    "            merged[col] = pd.to_numeric(merged[col], errors=\"coerce\")\n",
    "        elif dtype == \"datetime\":\n",
    "            merged[col] = pd.to_datetime(merged[col], errors=\"coerce\")\n",
    "        print(f\"✔️ {col} converted to {dtype}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not convert {col} to {dtype}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b013b7e1-e846-4964-aeef-f6a93aad3375",
   "metadata": {},
   "source": [
    "Check for mispellings in each string column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18857692-51c7-4106-bc9e-6c8fd9c77903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      4\n",
       "1      3\n",
       "2      2\n",
       "3      4\n",
       "4      2\n",
       "      ..\n",
       "873    2\n",
       "874    1\n",
       "875    1\n",
       "876    1\n",
       "877    2\n",
       "Name: Quantity, Length: 878, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtype_map\n",
    "merged['Quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60a4f8c3-19a8-4e01-a23a-4e908b13f50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Branch</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Date</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Product</th>\n",
       "      <th>__source_file__</th>\n",
       "      <th>row_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>NYC</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>159.32</td>\n",
       "      <td>Socks</td>\n",
       "      <td>sales_2024-03.xlsx</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>NYC</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-03-22</td>\n",
       "      <td>159.05</td>\n",
       "      <td>Hat</td>\n",
       "      <td>sales_2024-03.xlsx</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>LA</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>159.24</td>\n",
       "      <td>Socks</td>\n",
       "      <td>sales_2024-02.xlsx</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>NYC</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-02-10</td>\n",
       "      <td>158.92</td>\n",
       "      <td>Hoodie</td>\n",
       "      <td>sales_2024-02.xlsx</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>NYC</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>159.70</td>\n",
       "      <td>Socks</td>\n",
       "      <td>sales_2024-02.xlsx</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Branch  Quantity       Date  Revenue Product     __source_file__  \\\n",
       "68     NYC         4 2024-03-07   159.32   Socks  sales_2024-03.xlsx   \n",
       "205    NYC         4 2024-03-22   159.05     Hat  sales_2024-03.xlsx   \n",
       "308     LA         4 2024-02-01   159.24   Socks  sales_2024-02.xlsx   \n",
       "380    NYC         4 2024-02-10   158.92  Hoodie  sales_2024-02.xlsx   \n",
       "491    NYC         4 2024-02-21   159.70   Socks  sales_2024-02.xlsx   \n",
       "\n",
       "     row_number  \n",
       "68           70  \n",
       "205         207  \n",
       "308           5  \n",
       "380          77  \n",
       "491         188  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def detect_numeric_outliers(data, iqr_multiplier=1.5):\n",
    "    numeric_cols = data.select_dtypes(include='number').columns\n",
    "    outlier_mask = pd.Series(False, index=data.index)\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        q1 = data[col].quantile(0.25)\n",
    "        q3 = data[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - iqr_multiplier * iqr\n",
    "        upper_bound = q3 + iqr_multiplier * iqr\n",
    "\n",
    "        col_outliers = (data[col] < lower_bound) | (data[col] > upper_bound)\n",
    "        outlier_mask |= col_outliers  # Combine masks across columns\n",
    "\n",
    "    outlier_indices = data.index[outlier_mask]\n",
    "    return outlier_indices\n",
    "\n",
    "\n",
    "merged.loc[detect_numeric_outliers(merged)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "235abea2-4abf-4061-aed1-c3508fc4e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_clean_text_columns(df: pd.DataFrame, dtype_map: dict, threshold: int = 30) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For string columns in dtype_map, find fuzzy matches above a threshold and ask the user how to resolve.\n",
    "    - If user says values are the same, prompt for a unified replacement.\n",
    "    - If user says values are different, prompt for individual replacements.\n",
    "    \"\"\"\n",
    "    for col in dtype_map:\n",
    "        if dtype_map[col] != \"string\":\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n🔍 Checking column: {col}\")\n",
    "        fixed_values = {}\n",
    "\n",
    "        while True:\n",
    "            unique_vals = df[col].dropna().unique().tolist()\n",
    "            unique_vals = sorted(set(unique_vals) - set(fixed_values.keys()), key=lambda x: str(x).lower())\n",
    "\n",
    "            pair_found = False\n",
    "            for i, val in enumerate(unique_vals):\n",
    "                matches = process.extract(val, unique_vals, scorer=fuzz.ratio, limit=None)\n",
    "                similar = [(other, score) for other, score, _ in matches if other != val and score >= threshold and other not in fixed_values]\n",
    "\n",
    "                for other, score in similar:\n",
    "                    pair_found = True\n",
    "                    val_loc = df[df[col] == val][[\"__source_file__\", \"row_number\"]].iloc[0]\n",
    "                    other_loc = df[df[col] == other][[\"__source_file__\", \"row_number\"]].iloc[0]\n",
    "\n",
    "                    print(f\"\\n🧐 Found similar values in '{col}':\")\n",
    "                    print(f\"  • '{val}'  → {val_loc['__source_file__']} (row {val_loc['row_number']})\")\n",
    "                    print(f\"  • '{other}' → {other_loc['__source_file__']} (row {other_loc['row_number']})\")\n",
    "                    print(f\"  Similarity: {score}%\")\n",
    "\n",
    "                    decision = input(\"Do these refer to the same thing? [Y]es / [N]o / [S]kip: \").strip().lower()\n",
    "\n",
    "                    if decision == 'y':\n",
    "                        replacement = input(f\"What should both '{val}' and '{other}' be changed to? [default: '{val}']: \").strip()\n",
    "                        if not replacement:\n",
    "                            replacement = val\n",
    "                        df[col] = df[col].replace({val: replacement, other: replacement})\n",
    "                        fixed_values[val] = replacement\n",
    "                        fixed_values[other] = replacement\n",
    "                        print(f\"✅ Replaced both with '{replacement}'\")\n",
    "                        break  # rerun from start after update\n",
    "\n",
    "                    elif decision == 'n':\n",
    "                        new_val = input(f\"What should '{val}' be changed to? [Enter to keep]: \").strip()\n",
    "                        if new_val:\n",
    "                            df[col] = df[col].replace(val, new_val)\n",
    "                            fixed_values[val] = new_val\n",
    "                            print(f\"✅ '{val}' replaced with '{new_val}'\")\n",
    "                        else:\n",
    "                            fixed_values[val] = val  # Mark as seen\n",
    "\n",
    "                        new_other = input(f\"What should '{other}' be changed to? [Enter to keep]: \").strip()\n",
    "                        if new_other:\n",
    "                            df[col] = df[col].replace(other, new_other)\n",
    "                            fixed_values[other] = new_other\n",
    "                            print(f\"✅ '{other}' replaced with '{new_other}'\")\n",
    "                        else:\n",
    "                            fixed_values[other] = other  # Mark as seen\n",
    "                        break  # rerun from start after update\n",
    "\n",
    "                    else:\n",
    "                        print(\"⏭️ Skipped.\")\n",
    "                        fixed_values[val] = val\n",
    "                        fixed_values[other] = other\n",
    "                        break  # Continue to next match\n",
    "\n",
    "                if pair_found:\n",
    "                    break  # Rerun with updated values\n",
    "\n",
    "            if not pair_found:\n",
    "                print(f\"✅ No more fuzzy matches found in '{col}'.\")\n",
    "                break\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79236585-af3f-4f07-a3fd-fe6ed4327b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Checking column: Product\n",
      "✅ No more fuzzy matches found in 'Product'.\n",
      "\n",
      "🔍 Checking column: Branch\n",
      "\n",
      "🧐 Found similar values in 'Branch':\n",
      "  • 'LA'  → sales_2024-03.xlsx (row 7)\n",
      "  • 'Lac' → sales_2024-01.xlsx (row 3)\n",
      "  Similarity: 40.0%\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do these refer to the same thing? [Y]es / [N]o / [S]kip:  Y\n",
      "What should both 'LA' and 'Lac' be changed to? [default: 'LA']:  LA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Replaced both with 'LA'\n",
      "\n",
      "🧐 Found similar values in 'Branch':\n",
      "  • 'Las'  → sales_2024-01.xlsx (row 7)\n",
      "  • 'Law' → sales_2024-01.xlsx (row 2)\n",
      "  Similarity: 66.66666666666667%\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do these refer to the same thing? [Y]es / [N]o / [S]kip:  N\n",
      "What should 'Las' be changed to? [Enter to keep]:  LA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'Las' replaced with 'LA'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What should 'Law' be changed to? [Enter to keep]:  LA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'Law' replaced with 'LA'\n",
      "\n",
      "🧐 Found similar values in 'Branch':\n",
      "  • 'New York'  → sales_2024-01.xlsx (row 5)\n",
      "  • 'NYC' → sales_2024-03.xlsx (row 2)\n",
      "  Similarity: 36.36363636363637%\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do these refer to the same thing? [Y]es / [N]o / [S]kip:  Y\n",
      "What should both 'New York' and 'NYC' be changed to? [default: 'New York']:  NYC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Replaced both with 'NYC'\n",
      "✅ No more fuzzy matches found in 'Branch'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Date</th>\n",
       "      <th>__source_file__</th>\n",
       "      <th>row_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>125.92</td>\n",
       "      <td>NYC</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>sales_2024-03.xlsx</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hat</td>\n",
       "      <td>98.13</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>sales_2024-03.xlsx</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hat</td>\n",
       "      <td>77.36</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>sales_2024-03.xlsx</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Socks</td>\n",
       "      <td>96.67</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>sales_2024-03.xlsx</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hat</td>\n",
       "      <td>37.17</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>sales_2024-03.xlsx</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>Hat</td>\n",
       "      <td>44.70</td>\n",
       "      <td>LA</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>sales_2024-01.xlsx</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>Socks</td>\n",
       "      <td>20.39</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>sales_2024-01.xlsx</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>23.79</td>\n",
       "      <td>NYC</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>sales_2024-01.xlsx</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>Socks</td>\n",
       "      <td>36.67</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>sales_2024-01.xlsx</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>25.24</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>sales_2024-01.xlsx</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>878 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Product  Revenue   Branch  Quantity       Date     __source_file__  \\\n",
       "0    T-Shirt   125.92      NYC         4 2024-03-01  sales_2024-03.xlsx   \n",
       "1        Hat    98.13  Chicago         3 2024-03-01  sales_2024-03.xlsx   \n",
       "2        Hat    77.36  Chicago         2 2024-03-01  sales_2024-03.xlsx   \n",
       "3      Socks    96.67  Chicago         4 2024-03-01  sales_2024-03.xlsx   \n",
       "4        Hat    37.17  Chicago         2 2024-03-01  sales_2024-03.xlsx   \n",
       "..       ...      ...      ...       ...        ...                 ...   \n",
       "873      Hat    44.70       LA         2 2024-01-31  sales_2024-01.xlsx   \n",
       "874    Socks    20.39  Chicago         1 2024-01-31  sales_2024-01.xlsx   \n",
       "875  T-Shirt    23.79      NYC         1 2024-01-31  sales_2024-01.xlsx   \n",
       "876    Socks    36.67  Chicago         1 2024-01-31  sales_2024-01.xlsx   \n",
       "877  T-Shirt    25.24  Chicago         2 2024-01-31  sales_2024-01.xlsx   \n",
       "\n",
       "     row_number  \n",
       "0             2  \n",
       "1             3  \n",
       "2             4  \n",
       "3             5  \n",
       "4             6  \n",
       "..          ...  \n",
       "873         303  \n",
       "874         304  \n",
       "875         305  \n",
       "876         306  \n",
       "877         307  \n",
       "\n",
       "[878 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzy_clean_text_columns(merged,dtype_map,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22afec4e-e5c4-4614-a07e-18e2fbd8a735",
   "metadata": {},
   "source": [
    "Check for duplicates and allow user to decide how to proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0abfc016-5f9a-4a82-a14d-cd9256ecb6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_duplicates(data: pd.DataFrame, row_id_col: str = \"row_number\") -> pd.DataFrame:\n",
    "    # Columns to check for duplicates (exclude row_id_col if present)\n",
    "    cols_to_check = [col for col in data.columns if col != row_id_col]\n",
    "\n",
    "    # Find all exact duplicates based on relevant columns\n",
    "    duplicate_mask = data.duplicated(subset=cols_to_check, keep=False)\n",
    "    duplicates = data[duplicate_mask].copy()\n",
    "    non_duplicates = data[~duplicate_mask].copy()\n",
    "\n",
    "    if duplicates.empty:\n",
    "        print(\"✅ No duplicates found.\")\n",
    "        return data\n",
    "\n",
    "    # Assign a group number to each duplicate set\n",
    "    duplicates[\"group_num\"] = (\n",
    "        duplicates.groupby(cols_to_check, sort=False).ngroup() + 1\n",
    "    )\n",
    "\n",
    "    cleaned_rows = []\n",
    "\n",
    "    for group_id, group_df in duplicates.groupby(\"group_num\", sort=False):\n",
    "        print(f\"\\n🔍 Duplicate Group #{group_id}\")\n",
    "        print(group_df.to_string(index=False))\n",
    "\n",
    "        # Prompt user\n",
    "        while True:\n",
    "            decision = input(\"Keep all rows (K) or remove duplicates (R)? \").strip().lower()\n",
    "            if decision in {\"k\", \"r\"}:\n",
    "                break\n",
    "            print(\"Please enter 'K' to keep all rows or 'R' to remove duplicates.\")\n",
    "\n",
    "        if decision == \"k\":\n",
    "            cleaned_rows.append(group_df.drop(columns=\"group_num\"))\n",
    "        else:\n",
    "            cleaned_rows.append(group_df.iloc[[0]].drop(columns=\"group_num\"))\n",
    "\n",
    "    # Combine cleaned rows with non-duplicates\n",
    "    final_df = pd.concat([*cleaned_rows, non_duplicates], ignore_index=True)\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbdbe706-2539-414a-98de-545f1070e533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Duplicate Group #1\n",
      "Product  Revenue  Branch  Quantity       Date    __source_file__  row_number  group_num\n",
      "T-Shirt     40.7 Chicago         2 2024-01-01 sales_2024-01.xlsx           8          1\n",
      "T-Shirt     40.7 Chicago         2 2024-01-01 sales_2024-01.xlsx           9          1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Keep all rows (K) or remove duplicates (R)?  R\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Duplicate Group #2\n",
      "Product  Revenue Branch  Quantity       Date    __source_file__  row_number  group_num\n",
      " Hoodie    52.16    NYC         4 2024-01-02 sales_2024-01.xlsx          16          2\n",
      " Hoodie    52.16    NYC         4 2024-01-02 sales_2024-01.xlsx          27          2\n",
      " Hoodie    52.16    NYC         4 2024-01-02 sales_2024-01.xlsx          31          2\n",
      " Hoodie    52.16    NYC         4 2024-01-02 sales_2024-01.xlsx          34          2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Keep all rows (K) or remove duplicates (R)?  R\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Date</th>\n",
       "      <th>__source_file__</th>\n",
       "      <th>row_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>40.70</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>sales_2024-01.xlsx</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hoodie</td>\n",
       "      <td>52.16</td>\n",
       "      <td>NYC</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>sales_2024-01.xlsx</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>125.92</td>\n",
       "      <td>NYC</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>sales_2024-03.xlsx</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hat</td>\n",
       "      <td>98.13</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>sales_2024-03.xlsx</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hat</td>\n",
       "      <td>77.36</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>sales_2024-03.xlsx</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>Hat</td>\n",
       "      <td>44.70</td>\n",
       "      <td>LA</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>sales_2024-01.xlsx</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>Socks</td>\n",
       "      <td>20.39</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>sales_2024-01.xlsx</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>23.79</td>\n",
       "      <td>NYC</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>sales_2024-01.xlsx</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>Socks</td>\n",
       "      <td>36.67</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>sales_2024-01.xlsx</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>T-Shirt</td>\n",
       "      <td>25.24</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>sales_2024-01.xlsx</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>874 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Product  Revenue   Branch  Quantity       Date     __source_file__  \\\n",
       "0    T-Shirt    40.70  Chicago         2 2024-01-01  sales_2024-01.xlsx   \n",
       "1     Hoodie    52.16      NYC         4 2024-01-02  sales_2024-01.xlsx   \n",
       "2    T-Shirt   125.92      NYC         4 2024-03-01  sales_2024-03.xlsx   \n",
       "3        Hat    98.13  Chicago         3 2024-03-01  sales_2024-03.xlsx   \n",
       "4        Hat    77.36  Chicago         2 2024-03-01  sales_2024-03.xlsx   \n",
       "..       ...      ...      ...       ...        ...                 ...   \n",
       "869      Hat    44.70       LA         2 2024-01-31  sales_2024-01.xlsx   \n",
       "870    Socks    20.39  Chicago         1 2024-01-31  sales_2024-01.xlsx   \n",
       "871  T-Shirt    23.79      NYC         1 2024-01-31  sales_2024-01.xlsx   \n",
       "872    Socks    36.67  Chicago         1 2024-01-31  sales_2024-01.xlsx   \n",
       "873  T-Shirt    25.24  Chicago         2 2024-01-31  sales_2024-01.xlsx   \n",
       "\n",
       "     row_number  \n",
       "0             8  \n",
       "1            16  \n",
       "2             2  \n",
       "3             3  \n",
       "4             4  \n",
       "..          ...  \n",
       "869         303  \n",
       "870         304  \n",
       "871         305  \n",
       "872         306  \n",
       "873         307  \n",
       "\n",
       "[874 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = resolve_duplicates(merged)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f494747-67ef-4027-a23a-5cdb00f391c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
